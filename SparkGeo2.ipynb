{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a4f79bd",
   "metadata": {},
   "source": [
    "### Notebook to demo converting a Spark BDT Dataframe to a Feature Class Using Arrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77974367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import arcpy\n",
    "import pyarrow as pa\n",
    "\n",
    "import sparkgeo.functions as S\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pathlib import Path\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ddc223",
   "metadata": {},
   "source": [
    "### Create a Spark Session.\n",
    "\n",
    "Note how `arrow` is enabled and a \"window\" will appear. This will NOT happen with GAE :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e361031",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_java_options = \"-XX:+UseCompressedOops -XX:+AggressiveHeap\"\n",
    "\n",
    "jars = str(Path.home() / \"sparkgeo-3.2-0.53\" / \"sparkgeo-3.2-0.53.jar\")\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\", \"16G\")\\\n",
    "    .config(\"spark.executor.memory\", \"16G\")\\\n",
    "    .config(\"spark.driver.extraJavaOptions\", extra_java_options)\\\n",
    "    .config(\"spark.executor.extraJavaOptions\", extra_java_options)\\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"in-memory\")\\\n",
    "    .config(\"spark.sql.execution.arrow.enabled\", True)\\\n",
    "    .config(\"spark.ui.enabled\", False)\\\n",
    "    .config(\"spark.ui.showConsoleProgress\", True)\\\n",
    "    .config(\"spark.jars\", jars)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6582629",
   "metadata": {},
   "source": [
    "### Defined SR in WKT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_wkt = \"\"\"\n",
    "PROJCS[\"WGS_1984_Web_Mercator_Auxiliary_Sphere\",\n",
    "    GEOGCS[\"GCS_WGS_1984\",\n",
    "        DATUM[\"D_WGS_1984\",\n",
    "            SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],\n",
    "        PRIMEM[\"Greenwich\",0.0],\n",
    "        UNIT[\"Degree\",0.0174532925199433]],\n",
    "    PROJECTION[\"Mercator_Auxiliary_Sphere\"],\n",
    "    PARAMETER[\"False_Easting\",0.0],\n",
    "    PARAMETER[\"False_Northing\",0.0],\n",
    "    PARAMETER[\"Central_Meridian\",0.0],\n",
    "    PARAMETER[\"Standard_Parallel_1\",0.0],\n",
    "    PARAMETER[\"Auxiliary_Sphere_Type\",0.0],\n",
    "    UNIT[\"Meter\",1.0]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e750deba",
   "metadata": {},
   "source": [
    "### Define shape column metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_shp = {'esri.encoding' : 'EsriShape', 'esri.sr_wkt': sr_wkt}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122a5262",
   "metadata": {},
   "source": [
    "### Create arrow table schema.\n",
    "\n",
    "Note how we defined the fields nullability and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d3f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    pa.field(\"SHAPE\", pa.binary(), nullable=False, metadata=metadata_shp),\n",
    "    pa.field(\"x\", pa.float64(), nullable=False),\n",
    "    pa.field(\"y\", pa.float64(), nullable=False)\n",
    "]\n",
    "\n",
    "schema = pa.schema(fields)\n",
    "# schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04483af8",
   "metadata": {},
   "source": [
    "### Create a spark dataframe of points and make sure the column order is the same as in the arrow schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20821d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark\\\n",
    "    .range(100_000)\\\n",
    "    .select(S.lon_to_x(F.rand()*360-180).alias(\"x\"),S.lat_to_y(F.rand()*180-90).alias(\"y\"))\\\n",
    "    .withColumn(\"SHAPE\", S.st_as_esrishape(S.st_point(\"x\",\"y\")))\\\n",
    "    .select(\"SHAPE\",\"x\",\"y\")\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f88e945",
   "metadata": {},
   "source": [
    "### Get Spark DF as Arrow (Thanks Jordan :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66705c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = df._collect_as_arrow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319b7c1d",
   "metadata": {},
   "source": [
    "### Create Arrow table with explicit schema, as metadata is missing :-("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e48cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pa.Table.from_batches(batches, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tab.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0924aa",
   "metadata": {},
   "source": [
    "### Create ephemeral feature class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = os.path.join(\"memory\",\"SparkPoints\")\n",
    "arcpy.management.Delete(fc)\n",
    "arcpy.management.CopyFeatures(tab, fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7031011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.write.parquet(\"delete_me.prq\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.read.parquet(\"delete_me.prq\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
